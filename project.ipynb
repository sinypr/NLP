{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TRAVEL BOT using DEEP LEARNING\n",
        "BY: SINY P RAPHEL"
      ],
      "metadata": {
        "id": "U7kOFy-V6m7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMPORT NECESSARY PACKAGES"
      ],
      "metadata": {
        "id": "QfPL8djf7AQy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vuedeOkdDHtR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "# import nltk\n",
        "# import re\n",
        "# #nltk.download('stopwords')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#!pip install colorama\n",
        "import colorama \n",
        "colorama.init()\n",
        "from colorama import Fore, Style, Back\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDsD9CqmG6v7"
      },
      "source": [
        "### DATA LOAD\n",
        "The data is stored as a json file in the same folder in the drive. json.load() used to extract data from the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Oz-20ev4Kz4J"
      },
      "outputs": [],
      "source": [
        "data_dir = \"drive/MyDrive/NLP_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DRE0LyheEDak"
      },
      "outputs": [],
      "source": [
        "with open(data_dir+'data.json') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA PREPROCESSING\n",
        "Each feature is extracted from the dictionary and saved into lists."
      ],
      "metadata": {
        "id": "QV-wynFs7zkx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tksgCMitEQHC"
      },
      "outputs": [],
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "labels = []\n",
        "responses = []\n",
        "\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        training_sentences.append(pattern)\n",
        "        training_labels.append(intent['tag'])\n",
        "    responses.append(intent['responses'])\n",
        "    \n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n",
        "        \n",
        "num_classes = len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target is encoded using the LabelEncoder()"
      ],
      "metadata": {
        "id": "UQAyQ3f_8NhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Biv_B_CGHwBE"
      },
      "outputs": [],
      "source": [
        "lbl_encoder = LabelEncoder()\n",
        "lbl_encoder.fit(training_labels)\n",
        "training_labels = lbl_encoder.transform(training_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATA FEATURE EXTRACTION\n",
        "The data is \n",
        "* converted to lower case\n",
        "* removed punctuations\n",
        "* out-of-vocabulary words handled\n",
        "* converted to tokens and padded"
      ],
      "metadata": {
        "id": "C9TQwRp78ZRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZqbNF2ksL1pL"
      },
      "outputs": [],
      "source": [
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_len = 20\n",
        "oov_token = \"<OOV>\"\n",
        "\n",
        "#training_sentences = normalize_corpus(training_sentences)\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token, lower=True)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL TRAINING\n",
        "Sequential() class of Keras package is used for training the data. The model consists of one input layer, two hidden layers and one output layer.\n",
        "The loss is set to sparse crossentropy and the performance evaluated using \"accuracy\""
      ],
      "metadata": {
        "id": "K4kKrm9d9AKf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3Hu5XJgFMCx8",
        "outputId": "2a252c36-f28e-426e-93d0-6a003ff91d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 16)            16000     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 16)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 9)                 153       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,697\n",
            "Trainable params: 16,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL EVALUATION\n",
        "Epoch is set to 500. To limit the epoch to be printed a print_epoch variable is assigned and a call back function is developed."
      ],
      "metadata": {
        "id": "WGWTO5yW9vvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "print_epoch = 100"
      ],
      "metadata": {
        "id": "wXLq7LciQeOn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Callback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      # if epoch count is a multiple of assigned print_epoch value, print the values\n",
        "      if epoch % print_epoch == 0:\n",
        "        print(f\"Epoch {epoch} : Loss is {logs['loss']} and Accuracy is {logs['accuracy']}\")\n",
        "      elif epoch == epochs-1:\n",
        "        print(f\"Epoch {epoch+1} : Loss is {logs['loss']} and Accuracy is {logs['accuracy']}\")"
      ],
      "metadata": {
        "id": "wYBoHP8ICvXi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0M9XedazMFUF",
        "outputId": "efb74dea-02bb-423c-b4cd-d5619b2ee008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : Loss is 2.1964285373687744 and Accuracy is 0.1666666716337204\n",
            "Epoch 100 : Loss is 1.9513945579528809 and Accuracy is 0.3611111044883728\n",
            "Epoch 200 : Loss is 1.2899298667907715 and Accuracy is 0.4444444477558136\n",
            "Epoch 300 : Loss is 0.8568596243858337 and Accuracy is 0.8055555820465088\n",
            "Epoch 400 : Loss is 0.5128582715988159 and Accuracy is 0.9166666865348816\n",
            "Epoch 500 : Loss is 0.3006773293018341 and Accuracy is 0.9444444179534912\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs, verbose=0, callbacks=[Callback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is always 1 and there is no point in considering the accuracy. We can see that the loss reduces as the epochs increases."
      ],
      "metadata": {
        "id": "LUbhqa33RKnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot\n",
        "The function chat() runs utilizes the trained model and initializes the chatbot"
      ],
      "metadata": {
        "id": "pFrYVKvTRbxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mtiawEQ_M-ss",
        "outputId": "24de0566-1480-4060-9b5b-d3594c7d9fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start messaging with the bot (type quit to stop)!\n",
            "User: hello\n",
            "ChatBot: Hi\n",
            "User: whats your name\n",
            "ChatBot: Just call me as TravBot\n",
            "User: hellonTrav\n",
            "ChatBot: Tell me how can assist you\n",
            "User: hello trav\n",
            "ChatBot: Hi\n",
            "User: sign up for airline perk card\n",
            "ChatBot: Yes you can, I can help you to create one\n",
            "User: thank you\n",
            "ChatBot: My pleasure\n",
            "User: quit\n"
          ]
        }
      ],
      "source": [
        "def chat():\n",
        "    # parameters\n",
        "    max_len = 20\n",
        "    \n",
        "    while True:\n",
        "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
        "        inp = input()\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
        "                                             truncating='post', maxlen=max_len))\n",
        "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "\n",
        "        for i in data['intents']:\n",
        "            if i['tag'] == tag:\n",
        "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
        "\n",
        "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
        "\n",
        "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
        "chat()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}